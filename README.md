# ğŸ§  Multi-Model RAG - Notebook Implementation

This project demonstrates a **Multi-Model Retrieval-Augmented Generation (RAG)** pipeline using a Jupyter or Google Colab notebook. The system combines the power of multiple LLMs and retrieval strategies to generate high-quality, context-aware responses.

> ğŸ“˜ Sample data: The full text of the research paper **"Attention is All You Need"** (Vaswani et al., 2017) is used as the knowledge base for retrieval and question-answering.

---

## ğŸš€ Whatâ€™s Inside

- ğŸ“„ Load and chunk the "Attention is All You Need" paper
- ğŸ“š Embed the document using vector embeddings
- ğŸ” Perform semantic retrieval using vector similarity
- ğŸ§  Query using **multiple LLMs** (OpenAI, LLaMA, etc.)
- ğŸ”„ Switch between models or ensemble their outputs
- ğŸ§ª Interactive Q&A system inside the notebook

---

## âœ… Recommended Environment

For optimal performance and interactive capabilities, we recommend running this notebook in:

- ğŸ”¬ **Google Colab** â€“ [Try in Colab](https://colab.research.google.com)
- ğŸ’» **Jupyter Notebook** (locally with appropriate dependencies)

---
## Dependicies
Everything is mentioed in the Multimodal_RAG_System_with_GPT_4o.ipynb
