# 🧠 Multi-Model RAG - Notebook Implementation

This project demonstrates a **Multi-Model Retrieval-Augmented Generation (RAG)** pipeline using a Jupyter or Google Colab notebook. The system combines the power of multiple LLMs and retrieval strategies to generate high-quality, context-aware responses.

> 📘 Sample data: The full text of the research paper **"Attention is All You Need"** (Vaswani et al., 2017) is used as the knowledge base for retrieval and question-answering.

---

## 🚀 What’s Inside

- 📄 Load and chunk the "Attention is All You Need" paper
- 📚 Embed the document using vector embeddings
- 🔍 Perform semantic retrieval using vector similarity
- 🧠 Query using **multiple LLMs** (OpenAI, LLaMA, etc.)
- 🔄 Switch between models or ensemble their outputs
- 🧪 Interactive Q&A system inside the notebook

---

## ✅ Recommended Environment

For optimal performance and interactive capabilities, we recommend running this notebook in:

- 🔬 **Google Colab** – [Try in Colab](https://colab.research.google.com)
- 💻 **Jupyter Notebook** (locally with appropriate dependencies)

---
## Dependicies
Everything is mentioed in the Multimodal_RAG_System_with_GPT_4o.ipynb
